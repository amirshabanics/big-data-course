{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# MDA 2021\n",
        "## Pyspark Sample Code\n",
        "-----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "## Setup\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-qHai2252mI",
        "outputId": "4705761a-14d0-41b9-bce4-1737171658f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /home/amir/.local/lib/python3.8/site-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /home/amir/.local/lib/python3.8/site-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "# !pip install -U -q PyDrive\n",
        "# !apt install openjdk-8-jdk-headless -qq\n",
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh"
      },
      "source": [
        "Now we authenticate a Google Drive client to processing data\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K93ABEy9Zlo",
        "outputId": "67da4c0a-652e-40a3-8ced-bca3dc8ea999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bK7ob3k4Yd1"
      },
      "source": [
        "## Check and extract data\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT70OpRGzkWh",
        "outputId": "09a31c7c-7e5b-4c86-9040-3dff0dd1607e"
      },
      "outputs": [],
      "source": [
        "# !ls '/content/drive/MyDrive/SUT/Big Data/hw3'\n",
        "file_path = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLoUDlZrzoAg",
        "outputId": "16c0ec65-235c-4713-a4de-ff876139c591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./Sample_Data.zip\n",
            "replace ./Sample_Traffic.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip './Sample_Data' -d './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "the cells above, extract data which is in '/content/drive/My Drive/Test' to /content/drive/My Drive/Test/Traffic.csv  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "## Initializing Spark and read data\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "lDh957r_0snm"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
        "from pyspark.sql.functions import col, current_timestamp, to_date, hour, dayofweek\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Spark_Processor\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.executor.cores\", '6') \\\n",
        "    .config(\"spark.executor.memory\", '4900m') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"DEVICE_CODE\", IntegerType(), True),\n",
        "    StructField(\"SYSTEM_ID\", IntegerType(), True),\n",
        "    StructField(\"ORIGINE_CAR_KEY\", StringType(), True),\n",
        "    StructField(\"FINAL_CAR_KEY\", StringType(), True),\n",
        "    StructField(\"CHECK_STATUS_KEY\", IntegerType(), True),\n",
        "    StructField(\"COMPANY_ID\", StringType(), True),\n",
        "    StructField(\"PASS_DAY_TIME\", TimestampType(), True)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 dir=\"rtl\">\n",
        " خواندن دیتا\n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "CGoJ3OTX3Lz_",
        "outputId": "01eb8ac6-6d03-4ccd-870b-d28a22670e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|DEVICE_CODE|SYSTEM_ID|ORIGINE_CAR_KEY|FINAL_CAR_KEY|CHECK_STATUS_KEY|COMPANY_ID|      PASS_DAY_TIME|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|     200501|       81|       10477885|     10477885|               5|       161|2021-06-01 03:54:39|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=spark.read.csv(f'{file_path}Sample_Traffic.csv',header=True,schema=schema)\n",
        "df.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24N1Gd9O4GDi",
        "outputId": "22d78921-a60a-4967-9541-e54707bdbe46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Row(DEVICE_CODE=200501, SYSTEM_ID=81, ORIGINE_CAR_KEY='10477885', FINAL_CAR_KEY='10477885', CHECK_STATUS_KEY=5, COMPANY_ID='161', PASS_DAY_TIME=datetime.datetime(2021, 6, 1, 3, 54, 39))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3NG0x6oF2gy"
      },
      "source": [
        "<h1 dir=\"rtl\">\n",
        " الف \n",
        "</h1> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 dir=\"rtl\">\n",
        " خواندن \n",
        " <span dir=\"ltr\">\n",
        "   rdd \n",
        " </span> \n",
        "  دیتافریم و کش کردن آن \n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "YR3PaDw1GJfi",
        "outputId": "27e3fb5c-638f-4d81-fa8c-04d5cab8150a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MapPartitionsRDD[8] at javaToPython at NativeMethodAccessorImpl.java:0"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df.rdd\n",
        "data.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 dir=\"rtl\">\n",
        " بدست آوردن آیتم‌ها و سبد‌ها \n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " آیتم‌ها \n",
        "</h3> \n",
        "<h4 dir=\"rtl\">\n",
        " برای هر آیتم ما نیازمند پلاک شناسایی‌شده و روز به عنوان کلید و کد دوربین به عنوان مقدار آن نیازمندیم. باقی در این تمرین استفاده نمی‌شود. \n",
        "</h4> \n",
        "<h3 dir=\"rtl\">\n",
        " سبد‌ها\n",
        "</h3> \n",
        "<h4 dir=\"rtl\">\n",
        "ابتدا روی آیتم‌ها تابع \n",
        "<span dir=\"ltr\">\n",
        "  distinct\n",
        "</span> \n",
        "را صدا می‌زنیم. با اینکار آیتم‌های یکتا را می‌گیریم و سپس آن‌هایی که برای یک ماشین در یک روز خاص هستند را یک گروه می‌کنیم و کد‌ دستگاه‌ها را ذخیره می‌کنیم.\n",
        "</h4> \n",
        "<h3 dir=\"rtl\">\n",
        "  آیتم‌ها و سبد‌ها را کش می‌کنیم. دلیل استفاده از تابع \n",
        "  <span dir=\"ltr\">\n",
        "  distinct\n",
        "</span> \n",
        "، برای از بین بردن تکرار برای یک کلید مشابه است.\n",
        "به طور مثال ممکن است یک ماشین در یک روز خاص چندبار از یک‌محل رد شود.\n",
        "</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "VMorOlavGVF6",
        "outputId": "8051fe04-4908-4801-b3b6-fc7860ba266b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PythonRDD[18] at RDD at PythonRDD.scala:53"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (plate, date), route\n",
        "car_route_per_day_rdd = data.map(lambda x: (\n",
        "    (x.FINAL_CAR_KEY, x.PASS_DAY_TIME.date()), x.DEVICE_CODE))\n",
        "car_route_per_day_rdd.cache()\n",
        "# (plate, date), [route]\n",
        "car_routes_list_per_day_rdd = car_route_per_day_rdd.distinct().groupByKey().map(lambda x: tuple(x[1]))\n",
        "car_routes_list_per_day_rdd.cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnrYMm1OJA4s"
      },
      "source": [
        "<h1 dir=\"rtl\">\n",
        " ب \n",
        "</h1> \n",
        "<h2 dir=\"rtl\">\n",
        " پیاده‌سازی الگوریتم \n",
        " <span dir=\"ltr\">\n",
        "   a-priori\n",
        " </span> \n",
        "  \n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " دلیل اینکه ترشولد را خیلی بالا گرفتم این است که در انتهای ددلاین متوجه باگی در کدم شدم. برای اینکه شما خروجی از یک کد صحیح را ببینید مجبور به ران روی ترشولد پایین شدم. متاسفم. اما اگر روی 0.1 قرار دهید، مجموعه ۴ عضوی نیز خواهید داشت. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "4O5eJw_rJ0ob"
      },
      "outputs": [],
      "source": [
        "frequent_threshold = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUBqfXEcM3EN"
      },
      "source": [
        "<h3 dir=\"rtl\">\n",
        " یک تابع پیاده‌سازی می‌کنیم که  سبد‌ها و درصد ترشولد را ورودی بگیرد و خروجی لیستی از آیتم‌های پرتکرار بدهد. \n",
        " در حین اجرا لاگ‌هایی برای فهم بهتر مسئله چاپ می‌شود که زمان‌ها نشان‌دهنده زمانی که از آخرین باری که چاپ شده تا الان را نشان می‌دهد و بعضی از لاگ‌ها تعداد کاندید‌ها و بعضی‌ها تعداد پرتکرار‌های یک طول خاص را نشان می‌دهند.\n",
        "</h3> \n",
        "\n",
        "\n",
        "<h3 dir=\"rtl\">\n",
        " <ul dir=\"rtl\">\n",
        "  <li dir=\"rtl\">\n",
        "   ابتدا تعداد سبد‌ها را می‌شماریم و با اعمال ساده ریاضی ترشولد را بدست می‌آوریم. \n",
        "  </li> \n",
        "   <li dir=\"rtl\">\n",
        "    ابتدا نیاز داریم آیتم‌های پرتکرار با طول یک را بدست آوریم. از سبد‌ها تمام آیتم‌های متمایز را می‌خوانیم و سپس تعداد هرکدام را می‌شماریم. اگر از مقدار ترشولدمان بیشتر بود آن‌ها را انتخاب می‌کنیم. دلیل اینکه به صورت \n",
        "    <span dir=\"ltr\">\n",
        "      tuple\n",
        "    </span> \n",
        "     نگه‌داری می‌کنیم این است که اعمال اجتماع روی آن‌ها می‌توان استفاده کرد. همچنین نیاز به حالت‌بندی برای پرتکرار‌های طول ۲ با بقیه نیست.\n",
        "     <span dir=\"ltr\">\n",
        "       rdd\n",
        "     </span> \n",
        "     آن به عنوان پرتکرار ایتریشن خود ذخیره می‌کنیم و لیست آن را به عنوان نتیجه نهایی.\n",
        "   </li> \n",
        "   <li dir=\"rtl\">\n",
        "    حال ایتریشن را ۲ می‌کنیم. ایتریشن نشان می‌دهد که در حلقه دنبال پرتکرار‌ها با چه طولی هستیم. آنقدر این چرخه را ادامه می‌دهیم تا هیچ پرتکراری درآن نباشد.\n",
        "    <ol dir=\"rtl\">\n",
        "    <br/>\n",
        "     <li dir=\"rtl\">\n",
        "      مجموعه‌های پرتکرار ایتریشن قبل را در نظر بگیرید. آن‌ها را باهم کراس می‌کنیم. به عبارتی هرکدام را با دیگری جوین می‌کنیم. سپس با تابع پایتون \n",
        "      <span dir=\"ltr\">\n",
        "        set\n",
        "      </span> \n",
        "       مجموع آن را بدست می‌آوریم تا تکراری‌ها حذف شوند و دوباره آن را\n",
        "       <span dir=\"ltr\">\n",
        "         tuple\n",
        "       </span> \n",
        "       می‌کنیم. سپس آن‌هایی که طولشان برابر طول ایتریشن‌مان هستند را انتخاب می‌کنیم. چون در این حلقه قرار است مجموعه‌های پرتکرار که طولشان برابر ایتریشن است را انتخاب کنیم. دلیل اینکه کار درستی انجام می‌دهیم این است که اگر یک مجموعه پرتکرار باشد باید زیرمجموعه‌های یک طول کمتر آن‌ هم پرتکرار باشند. حال که ما تنها دو زیرمجموعه آن را بررسی کردیم نیز جزو کاندید‌های ما حساب می‌شود. البته که می‌توانیم برای کم‌تر کردن کاندید‌ها چک کنیم که همه زیرمجموعه‌های با یک طول کمتر پرتکرار باشند اما ما به همین‌قدر بسنده کرده‌ایم.\n",
        "     </li>   \n",
        "     <br/>\n",
        "     <li dir=\"rtl\">\n",
        "      سپس روی از هر سبد اگر کاندیدی در آن ظاهر شده‌است،\n",
        "      <span dir=\"ltr\">\n",
        "       (tuple_candidate, 1) \n",
        "      </span> \n",
        "       خروجی می‌دهیم. سپس این‌ها را باهم جمع می‌کنیم و از ترشولد استفاده می‌کنیم تا پرتکرار‌ها را بدست بیاوریم.\n",
        "     </li> \n",
        "     <br/>\n",
        "     <li dir=\"rtl\">\n",
        "       پرتکرار‌های بدست‌آمده را به نتایجمان اضافه می‌کنیم. ایتریشن را یک واحد اضافه می‌کنیم.\n",
        "     </li> \n",
        "    </ol> \n",
        "     \n",
        "   </li> \n",
        "   \n",
        " </ul> \n",
        "  \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.rdd import RDD\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def a_priori_algorithm(baskets: RDD, frequent_threshold: int = 5):\n",
        "    def get_candidate(basket):\n",
        "        basket_set = set(basket)\n",
        "        for iterset in candidate_frequent_iterset:\n",
        "            if set(iterset) <= basket_set:\n",
        "                yield (iterset, 1)\n",
        "\n",
        "    started_time = datetime.now()\n",
        "\n",
        "    total_baskets = baskets.count()\n",
        "    threshold = frequent_threshold * total_baskets / 100\n",
        "\n",
        "    frequent_itemset_length_one = baskets.flatMap(lambda x: list(set(x))).map(lambda x: (tuple([x]), 1)).reduceByKey(\n",
        "        lambda x, y: x+y).filter(lambda x: x[1] > threshold).map(lambda x: x[0]).filter(lambda x: len(x) == 1)\n",
        "    frequent_itemset_length_one.cache()\n",
        "\n",
        "    result_frequent_itemset = frequent_itemset_length_one.collect()\n",
        "    frequent_iterset_rdd = frequent_itemset_length_one\n",
        "\n",
        "    iter_length = 2\n",
        "    print(f\"{len(result_frequent_itemset)} frequent length one\")\n",
        "    while not frequent_iterset_rdd.isEmpty():\n",
        "\n",
        "        elapsed_time = datetime.now() - started_time\n",
        "        started_time = datetime.now()\n",
        "        print(f\"{iter_length} iteration:\", elapsed_time)\n",
        "        # candidate_frequent_iterset_rdd = frequent_iterset_rdd.cartesian(frequent_itemset_length_one).map(\n",
        "        #     lambda x: tuple(set(x[0] + x[1]))).filter(lambda x: len(x) == iter_length).distinct()\n",
        "\n",
        "        candidate_frequent_iterset_rdd = frequent_iterset_rdd.cartesian(frequent_iterset_rdd).map(\n",
        "            lambda x: tuple(sorted(list(set(x[0] + x[1]))))).filter(lambda x: len(x) == iter_length).distinct()\n",
        "\n",
        "        candidate_frequent_iterset = candidate_frequent_iterset_rdd.collect()\n",
        "\n",
        "        elapsed_time = datetime.now() - started_time\n",
        "        started_time = datetime.now()\n",
        "        print(f\"{len(candidate_frequent_iterset)} candidate\", elapsed_time)\n",
        "\n",
        "        frequent_iterset_rdd = baskets.flatMap(get_candidate).reduceByKey(\n",
        "            lambda x, y: x+y).filter(lambda x: x[1] > threshold).map(lambda x: x[0])\n",
        "\n",
        "        frequent_iterset = frequent_iterset_rdd.collect()\n",
        "\n",
        "        elapsed_time = datetime.now() - started_time\n",
        "        started_time = datetime.now()\n",
        "        print(f\"{len(frequent_iterset)} new frequent\", elapsed_time)\n",
        "\n",
        "        result_frequent_itemset.extend(frequent_iterset)\n",
        "        iter_length += 1\n",
        "\n",
        "    frequent_itemset_length_one.unpersist()\n",
        "\n",
        "    return result_frequent_itemset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 frequent length one\n",
            "2 iteration: 0:01:10.481343\n",
            "351 candidate 0:00:00.846577\n",
            "1 new frequent 0:00:26.912161\n",
            "3 iteration: 0:00:00.039071\n",
            "0 candidate 0:00:00.864092\n",
            "0 new frequent 0:00:00.445037\n"
          ]
        }
      ],
      "source": [
        "result_a_priori = a_priori_algorithm(car_routes_list_per_day_rdd, frequent_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(900107,),\n",
              " (900139,),\n",
              " (900155,),\n",
              " (100700824,),\n",
              " (900225,),\n",
              " (100700841,),\n",
              " (900222,),\n",
              " (900246,),\n",
              " (900142,),\n",
              " (900191,),\n",
              " (900207,),\n",
              " (22010119,),\n",
              " (100700804,),\n",
              " (900164,),\n",
              " (900268,),\n",
              " (900212,),\n",
              " (900244,),\n",
              " (900236,),\n",
              " (100700868,),\n",
              " (100700845,),\n",
              " (900269,),\n",
              " (900101,),\n",
              " (100700853,),\n",
              " (631357,),\n",
              " (100700866,),\n",
              " (900234,),\n",
              " (900202,),\n",
              " (900212, 900244)]"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_a_priori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 dir=\"rtl\">\n",
        " پ \n",
        "</h1> \n",
        "<h2 dir=\"rtl\">\n",
        " پیاده‌سازی \n",
        " <span dir=\"ltr\">\n",
        "  SON \n",
        " </span> \n",
        "  \n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        "برای اینکه سبد‌ها را به ۳ گروه تقسیم‌ کنیم، به صورت رندم برای هر سبد یک گروه انتخاب می‌کنیم. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random, math\n",
        "\n",
        "grouped_son = 3\n",
        "def random_mapper(x):\n",
        "    group = math.floor(random.random() * grouped_son) + 1\n",
        "    return (x, group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " در مراحل جلوتر چون نیاز‌مند چندبار اجرا روی\n",
        " <span dir=\"ltr\">\n",
        "  rdd \n",
        " </span> \n",
        " هستیم، آن را کش می‌کنیم. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_car_routes_list_per_day_rdd = car_routes_list_per_day_rdd.map(\n",
        "    random_mapper).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " تمام‌ آن‌هایی که در گروه خاص هستند را می‌گیریم. سپس  سبد‌های آن را بدست می‌آوریم. پس از آن الگوریتم\n",
        " <span dir=\"ltr\">\n",
        "  A-priori \n",
        " </span> \n",
        " که در بخش قبل پیاده‌سازی کردیم را با ترشولدی کمی کمتر اجرا می‌کنیم. نتیجه را در لیستی ذخیره می‌کنیم. پس از اینکه برای همه گرو‌ه‌ها انجام دادیم، لیست را به مجموعه و دوباره به لیست تبدیل می‌کنیم تا تکراری‌ها را حذف شوند.\n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Son iteration 0\n",
            "39 frequent length one\n",
            "2 iteration: 0:00:01.547617\n",
            "741 candidate 0:00:00.763600\n",
            "1 new frequent 0:00:18.932574\n",
            "3 iteration: 0:00:00.041469\n",
            "0 candidate 0:00:00.966228\n",
            "0 new frequent 0:00:00.225620\n",
            "\n",
            "Son iteration 1\n",
            "40 frequent length one\n",
            "2 iteration: 0:00:01.321733\n",
            "780 candidate 0:00:00.772662\n",
            "2 new frequent 0:00:19.973493\n",
            "3 iteration: 0:00:00.018946\n",
            "1 candidate 0:00:00.888922\n",
            "0 new frequent 0:00:00.232869\n",
            "\n",
            "Son iteration 2\n",
            "39 frequent length one\n",
            "2 iteration: 0:00:01.184068\n",
            "741 candidate 0:00:00.743994\n",
            "2 new frequent 0:00:19.401634\n",
            "3 iteration: 0:00:00.068504\n",
            "1 candidate 0:00:00.940920\n",
            "0 new frequent 0:00:00.258434\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result_son = []\n",
        "son_threshold = frequent_threshold*100/125\n",
        "for iteration in range(grouped_son):\n",
        "    print(f\"Son iteration {iteration}\")\n",
        "    son_basket_rdd = grouped_car_routes_list_per_day_rdd.filter(\n",
        "        lambda x: x[1] == iteration + 1).map(lambda x: x[0])\n",
        "    son_basket_rdd.cache()\n",
        "    result_son.extend(a_priori_algorithm(son_basket_rdd, son_threshold))\n",
        "\n",
        "    print('')\n",
        "\n",
        "result_son = list(set(result_son))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 dir=\"rtl\">\n",
        " چک نهایی برای از بین بردن مجموعه‌های پرتکرار اشتباه \n",
        "</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " برای اینکار نیاز داریم روی تمام سبد‌ها بچرخیم و اگر یکی از مجموعه‌های پرتکرار را داشت،\n",
        " <span dir=\"ltr\">\n",
        "  (frequent_itemset, 1) \n",
        " </span> \n",
        "  را به عنوان یکی از خروجی‌های \n",
        "  <span dir=\"ltr\">\n",
        "   flatMap \n",
        "  </span> \n",
        "  می‌دهیم.\n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_all_cadidate_son(basket):\n",
        "        basket_set = set(basket)\n",
        "        for iterset in result_son:\n",
        "            if set(iterset) <= basket_set:\n",
        "                yield (iterset, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " ترشولد را باتوجه به تعداد داده‌ها می‌سازیم تا چک کنیم. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_baskets = car_routes_list_per_day_rdd.count()\n",
        "son_final_check_threshold = frequent_threshold * all_baskets / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " در انتها جمع می‌کنیم تا ببینیم کدام‌ها واقعا مجموعه پرتکرار هستند. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_frequent_itemset_son = car_routes_list_per_day_rdd.flatMap(get_all_cadidate_son).reduceByKey(\n",
        "    lambda x, y: x+y).filter(lambda x: x[1] > son_final_check_threshold).map(lambda x: x[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_frequent_itemset_son.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_result_son = final_frequent_itemset_son.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 dir=\"rtl\">\n",
        " همانطور که انتظار داشتیم نتیجه هردو یکسان شده‌است. \n",
        "</h3> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(900107,),\n",
              " (900139,),\n",
              " (900155,),\n",
              " (100700824,),\n",
              " (900225,),\n",
              " (900212, 900244),\n",
              " (100700841,),\n",
              " (900222,),\n",
              " (900246,),\n",
              " (900142,),\n",
              " (900191,),\n",
              " (900207,),\n",
              " (22010119,),\n",
              " (100700804,),\n",
              " (900164,),\n",
              " (900268,),\n",
              " (900212,),\n",
              " (900244,),\n",
              " (900236,),\n",
              " (100700868,),\n",
              " (100700845,),\n",
              " (900269,),\n",
              " (900101,),\n",
              " (100700853,),\n",
              " (631357,),\n",
              " (100700866,),\n",
              " (900234,),\n",
              " (900202,)]"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_result_son"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MDA_2021.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
